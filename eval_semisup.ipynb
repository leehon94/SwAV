{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eval_semisup.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMeGzOMLYKMbLAWDGy0b2jZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leehon94/SwAV/blob/main/eval_semisup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "Ig52zsbLwuFJ",
        "outputId": "fdf53f72-fdcc-4036-cfb2-b52b503e3a82"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "from logging import getLogger\n",
        "import urllib\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from src.utils import (\n",
        "    bool_flag,\n",
        "    initialize_exp,\n",
        "    restart_from_checkpoint,\n",
        "    fix_random_seeds,\n",
        "    AverageMeter,\n",
        "    init_distributed_mode,\n",
        "    accuracy,\n",
        ")\n",
        "import src.resnet50 as resnet_models\n",
        "\n",
        "logger = getLogger()\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description=\"Evaluate models: Fine-tuning with 1% or 10% labels on ImageNet\")\n",
        "\n",
        "#########################\n",
        "#### main parameters ####\n",
        "#########################\n",
        "parser.add_argument(\"--labels_perc\", type=str, default=\"10\", choices=[\"1\", \"10\"],\n",
        "                    help=\"fine-tune on either 1% or 10% of labels\")\n",
        "parser.add_argument(\"--dump_path\", type=str, default=\".\",\n",
        "                    help=\"experiment dump path for checkpoints and log\")\n",
        "parser.add_argument(\"--seed\", type=int, default=31, help=\"seed\")\n",
        "parser.add_argument(\"--data_path\", type=str, default=\"/path/to/imagenet\",\n",
        "                    help=\"path to imagenet\")\n",
        "parser.add_argument(\"--workers\", default=10, type=int,\n",
        "                    help=\"number of data loading workers\")\n",
        "\n",
        "#########################\n",
        "#### model parameters ###\n",
        "#########################\n",
        "parser.add_argument(\"--arch\", default=\"resnet50\", type=str, help=\"convnet architecture\")\n",
        "parser.add_argument(\"--pretrained\", default=\"\", type=str, help=\"path to pretrained weights\")\n",
        "\n",
        "#########################\n",
        "#### optim parameters ###\n",
        "#########################\n",
        "parser.add_argument(\"--epochs\", default=20, type=int,\n",
        "                    help=\"number of total epochs to run\")\n",
        "parser.add_argument(\"--batch_size\", default=32, type=int,\n",
        "                    help=\"batch size per gpu, i.e. how many unique instances per gpu\")\n",
        "parser.add_argument(\"--lr\", default=0.01, type=float, help=\"initial learning rate - trunk\")\n",
        "parser.add_argument(\"--lr_last_layer\", default=0.2, type=float, help=\"initial learning rate - head\")\n",
        "parser.add_argument(\"--decay_epochs\", type=int, nargs=\"+\", default=[12, 16],\n",
        "                    help=\"Epochs at which to decay learning rate.\")\n",
        "parser.add_argument(\"--gamma\", type=float, default=0.2, help=\"lr decay factor\")\n",
        "\n",
        "#########################\n",
        "#### dist parameters ###\n",
        "#########################\n",
        "parser.add_argument(\"--dist_url\", default=\"env://\", type=str,\n",
        "                    help=\"url used to set up distributed training\")\n",
        "parser.add_argument(\"--world_size\", default=-1, type=int, help=\"\"\"\n",
        "                    number of processes: it is set automatically and\n",
        "                    should not be passed as argument\"\"\")\n",
        "parser.add_argument(\"--rank\", default=0, type=int, help=\"\"\"rank of this process:\n",
        "                    it is set automatically and should not be passed as argument\"\"\")\n",
        "parser.add_argument(\"--local_rank\", default=0, type=int,\n",
        "                    help=\"this argument is not used and should be ignored\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    global args, best_acc\n",
        "    args = parser.parse_args()\n",
        "    init_distributed_mode(args)\n",
        "    fix_random_seeds(args.seed)\n",
        "    logger, training_stats = initialize_exp(\n",
        "        args, \"epoch\", \"loss\", \"prec1\", \"prec5\", \"loss_val\", \"prec1_val\", \"prec5_val\"\n",
        "    )\n",
        "\n",
        "    # build data\n",
        "    train_data_path = os.path.join(args.data_path, \"train\")\n",
        "    train_dataset = datasets.ImageFolder(train_data_path)\n",
        "    # take either 1% or 10% of images\n",
        "    subset_file = urllib.request.urlopen(\"https://raw.githubusercontent.com/google-research/simclr/master/imagenet_subsets/\" + str(args.labels_perc) + \"percent.txt\")\n",
        "    list_imgs = [li.decode(\"utf-8\").split('\\n')[0] for li in subset_file]\n",
        "    train_dataset.samples = [(\n",
        "        os.path.join(train_data_path, li.split('_')[0], li),\n",
        "        train_dataset.class_to_idx[li.split('_')[0]]\n",
        "    ) for li in list_imgs]\n",
        "    val_dataset = datasets.ImageFolder(os.path.join(args.data_path, \"val\"))\n",
        "    tr_normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406], std=[0.228, 0.224, 0.225]\n",
        "    )\n",
        "    train_dataset.transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        tr_normalize,\n",
        "    ])\n",
        "    val_dataset.transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        tr_normalize,\n",
        "    ])\n",
        "    sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        sampler=sampler,\n",
        "        batch_size=args.batch_size,\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    logger.info(\"Building data done with {} images loaded.\".format(len(train_dataset)))\n",
        "\n",
        "    # build model\n",
        "    model = resnet_models.__dict__[args.arch](output_dim=1000)\n",
        "\n",
        "    # convert batch norm layers\n",
        "    model = nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
        "\n",
        "    # load weights\n",
        "    if os.path.isfile(args.pretrained):\n",
        "        state_dict = torch.load(args.pretrained, map_location=\"cuda:\" + str(args.gpu_to_work_on))\n",
        "        if \"state_dict\" in state_dict:\n",
        "            state_dict = state_dict[\"state_dict\"]\n",
        "        # remove prefixe \"module.\"\n",
        "        state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
        "        for k, v in model.state_dict().items():\n",
        "            if k not in list(state_dict):\n",
        "                logger.info('key \"{}\" could not be found in provided state dict'.format(k))\n",
        "            elif state_dict[k].shape != v.shape:\n",
        "                logger.info('key \"{}\" is of different shape in model and provided state dict'.format(k))\n",
        "                state_dict[k] = v\n",
        "        msg = model.load_state_dict(state_dict, strict=False)\n",
        "        logger.info(\"Load pretrained model with msg: {}\".format(msg))\n",
        "    else:\n",
        "        logger.info(\"No pretrained weights found => training from random weights\")\n",
        "\n",
        "    # model to gpu\n",
        "    model = model.cuda()\n",
        "    model = nn.parallel.DistributedDataParallel(\n",
        "        model,\n",
        "        device_ids=[args.gpu_to_work_on],\n",
        "        find_unused_parameters=True,\n",
        "    )\n",
        "\n",
        "    # set optimizer\n",
        "    trunk_parameters = []\n",
        "    head_parameters = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'head' in name:\n",
        "            head_parameters.append(param)\n",
        "        else:\n",
        "            trunk_parameters.append(param)\n",
        "    optimizer = torch.optim.SGD(\n",
        "        [{'params': trunk_parameters},\n",
        "         {'params': head_parameters, 'lr': args.lr_last_layer}],\n",
        "        lr=args.lr,\n",
        "        momentum=0.9,\n",
        "        weight_decay=0,\n",
        "    )\n",
        "    # set scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "        optimizer, args.decay_epochs, gamma=args.gamma\n",
        "    )\n",
        "\n",
        "    # Optionally resume from a checkpoint\n",
        "    to_restore = {\"epoch\": 0, \"best_acc\": (0., 0.)}\n",
        "    restart_from_checkpoint(\n",
        "        os.path.join(args.dump_path, \"checkpoint.pth.tar\"),\n",
        "        run_variables=to_restore,\n",
        "        state_dict=model,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "    )\n",
        "    start_epoch = to_restore[\"epoch\"]\n",
        "    best_acc = to_restore[\"best_acc\"]\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    for epoch in range(start_epoch, args.epochs):\n",
        "\n",
        "        # train the network for one epoch\n",
        "        logger.info(\"============ Starting epoch %i ... ============\" % epoch)\n",
        "\n",
        "        # set samplers\n",
        "        train_loader.sampler.set_epoch(epoch)\n",
        "\n",
        "        scores = train(model, optimizer, train_loader, epoch)\n",
        "        scores_val = validate_network(val_loader, model)\n",
        "        training_stats.update(scores + scores_val)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # save checkpoint\n",
        "        if args.rank == 0:\n",
        "            save_dict = {\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"state_dict\": model.state_dict(),\n",
        "                \"optimizer\": optimizer.state_dict(),\n",
        "                \"scheduler\": scheduler.state_dict(),\n",
        "                \"best_acc\": best_acc,\n",
        "            }\n",
        "            torch.save(save_dict, os.path.join(args.dump_path, \"checkpoint.pth.tar\"))\n",
        "    logger.info(\"Fine-tuning with {}% of labels completed.\\n\"\n",
        "                \"Test accuracies: top-1 {acc1:.1f}, top-5 {acc5:.1f}\".format(\n",
        "                args.labels_perc, acc1=best_acc[0], acc5=best_acc[1]))\n",
        "\n",
        "\n",
        "def train(model, optimizer, loader, epoch):\n",
        "    \"\"\"\n",
        "    Train the models on the dataset.\n",
        "    \"\"\"\n",
        "    # running statistics\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "\n",
        "    # training statistics\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    end = time.perf_counter()\n",
        "\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "    for iter_epoch, (inp, target) in enumerate(loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.perf_counter() - end)\n",
        "\n",
        "        # move to gpu\n",
        "        inp = inp.cuda(non_blocking=True)\n",
        "        target = target.cuda(non_blocking=True)\n",
        "\n",
        "        # forward\n",
        "        output = model(inp)\n",
        "\n",
        "        # compute cross entropy loss\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # compute the gradients\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # step\n",
        "        optimizer.step()\n",
        "\n",
        "        # update stats\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), inp.size(0))\n",
        "        top1.update(acc1[0], inp.size(0))\n",
        "        top5.update(acc5[0], inp.size(0))\n",
        "\n",
        "        batch_time.update(time.perf_counter() - end)\n",
        "        end = time.perf_counter()\n",
        "\n",
        "        # verbose\n",
        "        if args.rank == 0 and iter_epoch % 50 == 0:\n",
        "            logger.info(\n",
        "                \"Epoch[{0}] - Iter: [{1}/{2}]\\t\"\n",
        "                \"Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"\n",
        "                \"Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\"\n",
        "                \"Loss {loss.val:.4f} ({loss.avg:.4f})\\t\"\n",
        "                \"Prec {top1.val:.3f} ({top1.avg:.3f})\\t\"\n",
        "                \"LR trunk {lr}\\t\"\n",
        "                \"LR head {lr_W}\".format(\n",
        "                    epoch,\n",
        "                    iter_epoch,\n",
        "                    len(loader),\n",
        "                    batch_time=batch_time,\n",
        "                    data_time=data_time,\n",
        "                    loss=losses,\n",
        "                    top1=top1,\n",
        "                    lr=optimizer.param_groups[0][\"lr\"],\n",
        "                    lr_W=optimizer.param_groups[1][\"lr\"],\n",
        "                )\n",
        "            )\n",
        "    return epoch, losses.avg, top1.avg.item(), top5.avg.item()\n",
        "\n",
        "\n",
        "def validate_network(val_loader, model):\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    global best_acc\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        end = time.perf_counter()\n",
        "        for i, (inp, target) in enumerate(val_loader):\n",
        "\n",
        "            # move to gpu\n",
        "            inp = inp.cuda(non_blocking=True)\n",
        "            target = target.cuda(non_blocking=True)\n",
        "\n",
        "            # compute output\n",
        "            output = model(inp)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "            losses.update(loss.item(), inp.size(0))\n",
        "            top1.update(acc1[0], inp.size(0))\n",
        "            top5.update(acc5[0], inp.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.perf_counter() - end)\n",
        "            end = time.perf_counter()\n",
        "\n",
        "    if top1.avg.item() > best_acc[0]:\n",
        "        best_acc = (top1.avg.item(), top5.avg.item())\n",
        "\n",
        "    if args.rank == 0:\n",
        "        logger.info(\n",
        "            \"Test:\\t\"\n",
        "            \"Time {batch_time.avg:.3f}\\t\"\n",
        "            \"Loss {loss.avg:.4f}\\t\"\n",
        "            \"Acc@1 {top1.avg:.3f}\\t\"\n",
        "            \"Best Acc@1 so far {acc:.1f}\".format(\n",
        "                batch_time=batch_time, loss=losses, top1=top1, acc=best_acc[0]))\n",
        "\n",
        "    return losses.avg, top1.avg.item(), top5.avg.item()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1981fff841d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m from src.utils import (\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mbool_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0minitialize_exp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}
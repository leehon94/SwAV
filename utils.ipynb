{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "utils.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOWQ449j+6mCpJ+LUDkMOYw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leehon94/SwAV/blob/main/utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "4bDwErGk0GrW",
        "outputId": "4698cd70-f968-4e6a-b502-5b0ae4c81aa3"
      },
      "source": [
        "import argparse\n",
        "from logging import getLogger\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from .logger import create_logger, PD_Stats\n",
        "\n",
        "import torch.distributed as dist\n",
        "\n",
        "FALSY_STRINGS = {\"off\", \"false\", \"0\"}\n",
        "TRUTHY_STRINGS = {\"on\", \"true\", \"1\"}\n",
        "\n",
        "\n",
        "logger = getLogger()\n",
        "\n",
        "\n",
        "def bool_flag(s):\n",
        "    \"\"\"\n",
        "    Parse boolean arguments from the command line.\n",
        "    \"\"\"\n",
        "    if s.lower() in FALSY_STRINGS:\n",
        "        return False\n",
        "    elif s.lower() in TRUTHY_STRINGS:\n",
        "        return True\n",
        "    else:\n",
        "        raise argparse.ArgumentTypeError(\"invalid value for a boolean flag\")\n",
        "\n",
        "\n",
        "def init_distributed_mode(args):\n",
        "    \"\"\"\n",
        "    Initialize the following variables:\n",
        "        - world_size\n",
        "        - rank\n",
        "    \"\"\"\n",
        "\n",
        "    args.is_slurm_job = \"SLURM_JOB_ID\" in os.environ\n",
        "\n",
        "    if args.is_slurm_job:\n",
        "        args.rank = int(os.environ[\"SLURM_PROCID\"])\n",
        "        args.world_size = int(os.environ[\"SLURM_NNODES\"]) * int(\n",
        "            os.environ[\"SLURM_TASKS_PER_NODE\"][0]\n",
        "        )\n",
        "    else:\n",
        "        # multi-GPU job (local or multi-node) - jobs started with torch.distributed.launch\n",
        "        # read environment variables\n",
        "        args.rank = int(os.environ[\"RANK\"])\n",
        "        args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
        "\n",
        "    # prepare distributed\n",
        "    dist.init_process_group(\n",
        "        backend=\"nccl\",\n",
        "        init_method=args.dist_url,\n",
        "        world_size=args.world_size,\n",
        "        rank=args.rank,\n",
        "    )\n",
        "\n",
        "    # set cuda device\n",
        "    args.gpu_to_work_on = args.rank % torch.cuda.device_count()\n",
        "    torch.cuda.set_device(args.gpu_to_work_on)\n",
        "    return\n",
        "\n",
        "\n",
        "def initialize_exp(params, *args, dump_params=True):\n",
        "    \"\"\"\n",
        "    Initialize the experience:\n",
        "    - dump parameters\n",
        "    - create checkpoint repo\n",
        "    - create a logger\n",
        "    - create a panda object to keep track of the training statistics\n",
        "    \"\"\"\n",
        "\n",
        "    # dump parameters\n",
        "    if dump_params:\n",
        "        pickle.dump(params, open(os.path.join(params.dump_path, \"params.pkl\"), \"wb\"))\n",
        "\n",
        "    # create repo to store checkpoints\n",
        "    params.dump_checkpoints = os.path.join(params.dump_path, \"checkpoints\")\n",
        "    if not params.rank and not os.path.isdir(params.dump_checkpoints):\n",
        "        os.mkdir(params.dump_checkpoints)\n",
        "\n",
        "    # create a panda object to log loss and acc\n",
        "    training_stats = PD_Stats(\n",
        "        os.path.join(params.dump_path, \"stats\" + str(params.rank) + \".pkl\"), args\n",
        "    )\n",
        "\n",
        "    # create a logger\n",
        "    logger = create_logger(\n",
        "        os.path.join(params.dump_path, \"train.log\"), rank=params.rank\n",
        "    )\n",
        "    logger.info(\"============ Initialized logger ============\")\n",
        "    logger.info(\n",
        "        \"\\n\".join(\"%s: %s\" % (k, str(v)) for k, v in sorted(dict(vars(params)).items()))\n",
        "    )\n",
        "    logger.info(\"The experiment will be stored in %s\\n\" % params.dump_path)\n",
        "    logger.info(\"\")\n",
        "    return logger, training_stats\n",
        "\n",
        "\n",
        "def restart_from_checkpoint(ckp_paths, run_variables=None, **kwargs):\n",
        "    \"\"\"\n",
        "    Re-start from checkpoint\n",
        "    \"\"\"\n",
        "    # look for a checkpoint in exp repository\n",
        "    if isinstance(ckp_paths, list):\n",
        "        for ckp_path in ckp_paths:\n",
        "            if os.path.isfile(ckp_path):\n",
        "                break\n",
        "    else:\n",
        "        ckp_path = ckp_paths\n",
        "\n",
        "    if not os.path.isfile(ckp_path):\n",
        "        return\n",
        "\n",
        "    logger.info(\"Found checkpoint at {}\".format(ckp_path))\n",
        "\n",
        "    # open checkpoint file\n",
        "    checkpoint = torch.load(\n",
        "        ckp_path, map_location=\"cuda:\" + str(torch.distributed.get_rank() % torch.cuda.device_count())\n",
        "    )\n",
        "\n",
        "    # key is what to look for in the checkpoint file\n",
        "    # value is the object to load\n",
        "    # example: {'state_dict': model}\n",
        "    for key, value in kwargs.items():\n",
        "        if key in checkpoint and value is not None:\n",
        "            try:\n",
        "                msg = value.load_state_dict(checkpoint[key], strict=False)\n",
        "                print(msg)\n",
        "            except TypeError:\n",
        "                msg = value.load_state_dict(checkpoint[key])\n",
        "            logger.info(\"=> loaded {} from checkpoint '{}'\".format(key, ckp_path))\n",
        "        else:\n",
        "            logger.warning(\n",
        "                \"=> failed to load {} from checkpoint '{}'\".format(key, ckp_path)\n",
        "            )\n",
        "\n",
        "    # re load variable important for the run\n",
        "    if run_variables is not None:\n",
        "        for var_name in run_variables:\n",
        "            if var_name in checkpoint:\n",
        "                run_variables[var_name] = checkpoint[var_name]\n",
        "\n",
        "\n",
        "def fix_random_seeds(seed=31):\n",
        "    \"\"\"\n",
        "    Fix random seeds.\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-144e40da9565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPD_Stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '__main__.logger'; '__main__' is not a package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}
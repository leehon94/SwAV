{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multicropdataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOoo01ctFLvx/j9+Z2B4Wrc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leehon94/SwAV/blob/main/multicropdataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euc7tHYFzagA"
      },
      "source": [
        "import random\n",
        "from logging import getLogger\n",
        "\n",
        "import cv2\n",
        "from PIL import ImageFilter\n",
        "import numpy as np\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "logger = getLogger()\n",
        "\n",
        "\n",
        "class MultiCropDataset(datasets.ImageFolder):\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_path,\n",
        "        size_crops,\n",
        "        nmb_crops,\n",
        "        min_scale_crops,\n",
        "        max_scale_crops,\n",
        "        size_dataset=-1,\n",
        "        return_index=False,\n",
        "        pil_blur=False,\n",
        "    ):\n",
        "        super(MultiCropDataset, self).__init__(data_path)\n",
        "        assert len(size_crops) == len(nmb_crops)\n",
        "        assert len(min_scale_crops) == len(nmb_crops)\n",
        "        assert len(max_scale_crops) == len(nmb_crops)\n",
        "        if size_dataset >= 0:\n",
        "            self.samples = self.samples[:size_dataset]\n",
        "        self.return_index = return_index\n",
        "\n",
        "        color_transform = [get_color_distortion(), RandomGaussianBlur()]\n",
        "        if pil_blur:\n",
        "            color_transform = [get_color_distortion(), PILRandomGaussianBlur()]\n",
        "        mean = [0.485, 0.456, 0.406]\n",
        "        std = [0.228, 0.224, 0.225]\n",
        "        trans = []\n",
        "        for i in range(len(size_crops)):\n",
        "            randomresizedcrop = transforms.RandomResizedCrop(\n",
        "                size_crops[i],\n",
        "                scale=(min_scale_crops[i], max_scale_crops[i]),\n",
        "            )\n",
        "            trans.extend([transforms.Compose([\n",
        "                randomresizedcrop,\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Compose(color_transform),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=mean, std=std)])\n",
        "            ] * nmb_crops[i])\n",
        "        self.trans = trans\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path, _ = self.samples[index]\n",
        "        image = self.loader(path)\n",
        "        multi_crops = list(map(lambda trans: trans(image), self.trans))\n",
        "        if self.return_index:\n",
        "            return index, multi_crops\n",
        "        return multi_crops\n",
        "\n",
        "\n",
        "class RandomGaussianBlur(object):\n",
        "    def __call__(self, img):\n",
        "        do_it = np.random.rand() > 0.5\n",
        "        if not do_it:\n",
        "            return img\n",
        "        sigma = np.random.rand() * 1.9 + 0.1\n",
        "        return cv2.GaussianBlur(np.asarray(img), (23, 23), sigma)\n",
        "\n",
        "\n",
        "class PILRandomGaussianBlur(object):\n",
        "    \"\"\"\n",
        "    Apply Gaussian Blur to the PIL image. Take the radius and probability of\n",
        "    application as the parameter.\n",
        "    This transform was used in SimCLR - https://arxiv.org/abs/2002.05709\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p=0.5, radius_min=0.1, radius_max=2.):\n",
        "        self.prob = p\n",
        "        self.radius_min = radius_min\n",
        "        self.radius_max = radius_max\n",
        "\n",
        "    def __call__(self, img):\n",
        "        do_it = np.random.rand() <= self.prob\n",
        "        if not do_it:\n",
        "            return img\n",
        "\n",
        "        return img.filter(\n",
        "            ImageFilter.GaussianBlur(\n",
        "                radius=random.uniform(self.radius_min, self.radius_max)\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "def get_color_distortion(s=1.0):\n",
        "    # s is the strength of color distortion.\n",
        "    color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
        "    rnd_color_jitter = transforms.RandomApply([color_jitter], p=0.8)\n",
        "    rnd_gray = transforms.RandomGrayscale(p=0.2)\n",
        "    color_distort = transforms.Compose([rnd_color_jitter, rnd_gray])\n",
        "    return color_distort"
      ],
      "execution_count": 1,
      "outputs": []
    }
  ]
}
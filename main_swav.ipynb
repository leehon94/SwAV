{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_swav.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPXfLnLYAM16f5Kb2viMKva",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leehon94/SwAV/blob/main/main_swav.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MI2hvmep7R3",
        "outputId": "068f42ca-d072-4b0d-911f-59d0ce9e6571"
      },
      "source": [
        "!pip install git+git://github.com/NVIDIA/apex.git@4a1aa97e31ca87514e17c3cd3bbc03f4204579d0 --install-option=\"--cuda_ext\""
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Collecting git+git://github.com/NVIDIA/apex.git@4a1aa97e31ca87514e17c3cd3bbc03f4204579d0\n",
            "  Cloning git://github.com/NVIDIA/apex.git (to revision 4a1aa97e31ca87514e17c3cd3bbc03f4204579d0) to /tmp/pip-req-build-hvwadzm_\n",
            "  Running command git clone -q git://github.com/NVIDIA/apex.git /tmp/pip-req-build-hvwadzm_\n",
            "  Running command git checkout -q 4a1aa97e31ca87514e17c3cd3bbc03f4204579d0\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "    Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed apex-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "JDQjVfVmlX4N",
        "outputId": "fe43de7c-5e3c-43ae-ed9b-a68dfafa60db"
      },
      "source": [
        "import argparse\n",
        "import math\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "from logging import getLogger\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "import torch.optim\n",
        "import apex\n",
        "from apex.parallel.LARC import LARC\n",
        "\n",
        "from src.utils import (\n",
        "    bool_flag,\n",
        "    initialize_exp,\n",
        "    restart_from_checkpoint,\n",
        "    fix_random_seeds,\n",
        "    AverageMeter,\n",
        "    init_distributed_mode,\n",
        ")\n",
        "from src.multicropdataset import MultiCropDataset\n",
        "import src.resnet50 as resnet_models\n",
        "\n",
        "logger = getLogger()\n",
        "\n",
        "parser = argparse.ArgumentParser(description=\"Implementation of SwAV\")\n",
        "\n",
        "#########################\n",
        "#### data parameters ####\n",
        "#########################\n",
        "parser.add_argument(\"--data_path\", type=str, default=\"/path/to/imagenet\",\n",
        "                    help=\"path to dataset repository\")\n",
        "parser.add_argument(\"--nmb_crops\", type=int, default=[2], nargs=\"+\",\n",
        "                    help=\"list of number of crops (example: [2, 6])\")\n",
        "parser.add_argument(\"--size_crops\", type=int, default=[224], nargs=\"+\",\n",
        "                    help=\"crops resolutions (example: [224, 96])\")\n",
        "parser.add_argument(\"--min_scale_crops\", type=float, default=[0.14], nargs=\"+\",\n",
        "                    help=\"argument in RandomResizedCrop (example: [0.14, 0.05])\")\n",
        "parser.add_argument(\"--max_scale_crops\", type=float, default=[1], nargs=\"+\",\n",
        "                    help=\"argument in RandomResizedCrop (example: [1., 0.14])\")\n",
        "parser.add_argument(\"--use_pil_blur\", type=bool_flag, default=True,\n",
        "                    help=\"\"\"use PIL library to perform blur instead of opencv\"\"\")\n",
        "\n",
        "#########################\n",
        "## swav specific params #\n",
        "#########################\n",
        "parser.add_argument(\"--crops_for_assign\", type=int, nargs=\"+\", default=[0, 1],\n",
        "                    help=\"list of crops id used for computing assignments\")\n",
        "parser.add_argument(\"--temperature\", default=0.1, type=float,\n",
        "                    help=\"temperature parameter in training loss\")\n",
        "parser.add_argument(\"--epsilon\", default=0.05, type=float,\n",
        "                    help=\"regularization parameter for Sinkhorn-Knopp algorithm\")\n",
        "parser.add_argument(\"--improve_numerical_stability\", default=False, type=bool_flag,\n",
        "                    help=\"improves numerical stability in Sinkhorn-Knopp algorithm\")\n",
        "parser.add_argument(\"--sinkhorn_iterations\", default=3, type=int,\n",
        "                    help=\"number of iterations in Sinkhorn-Knopp algorithm\")\n",
        "parser.add_argument(\"--feat_dim\", default=128, type=int,\n",
        "                    help=\"feature dimension\")\n",
        "parser.add_argument(\"--nmb_prototypes\", default=3000, type=int,\n",
        "                    help=\"number of prototypes\")\n",
        "parser.add_argument(\"--queue_length\", type=int, default=0,\n",
        "                    help=\"length of the queue (0 for no queue)\")\n",
        "parser.add_argument(\"--epoch_queue_starts\", type=int, default=15,\n",
        "                    help=\"from this epoch, we start using a queue\")\n",
        "\n",
        "#########################\n",
        "#### optim parameters ###\n",
        "#########################\n",
        "parser.add_argument(\"--epochs\", default=100, type=int,\n",
        "                    help=\"number of total epochs to run\")\n",
        "parser.add_argument(\"--batch_size\", default=64, type=int,\n",
        "                    help=\"batch size per gpu, i.e. how many unique instances per gpu\")\n",
        "parser.add_argument(\"--base_lr\", default=4.8, type=float, help=\"base learning rate\")\n",
        "parser.add_argument(\"--final_lr\", type=float, default=0, help=\"final learning rate\")\n",
        "parser.add_argument(\"--freeze_prototypes_niters\", default=313, type=int,\n",
        "                    help=\"freeze the prototypes during this many iterations from the start\")\n",
        "parser.add_argument(\"--wd\", default=1e-6, type=float, help=\"weight decay\")\n",
        "parser.add_argument(\"--warmup_epochs\", default=10, type=int, help=\"number of warmup epochs\")\n",
        "parser.add_argument(\"--start_warmup\", default=0, type=float,\n",
        "                    help=\"initial warmup learning rate\")\n",
        "\n",
        "#########################\n",
        "#### dist parameters ###\n",
        "#########################\n",
        "parser.add_argument(\"--dist_url\", default=\"env://\", type=str, help=\"\"\"url used to set up distributed\n",
        "                    training; see https://pytorch.org/docs/stable/distributed.html\"\"\")\n",
        "parser.add_argument(\"--world_size\", default=-1, type=int, help=\"\"\"\n",
        "                    number of processes: it is set automatically and\n",
        "                    should not be passed as argument\"\"\")\n",
        "parser.add_argument(\"--rank\", default=0, type=int, help=\"\"\"rank of this process:\n",
        "                    it is set automatically and should not be passed as argument\"\"\")\n",
        "parser.add_argument(\"--local_rank\", default=0, type=int,\n",
        "                    help=\"this argument is not used and should be ignored\")\n",
        "\n",
        "#########################\n",
        "#### other parameters ###\n",
        "#########################\n",
        "parser.add_argument(\"--arch\", default=\"resnet50\", type=str, help=\"convnet architecture\")\n",
        "parser.add_argument(\"--hidden_mlp\", default=2048, type=int,\n",
        "                    help=\"hidden layer dimension in projection head\")\n",
        "parser.add_argument(\"--workers\", default=10, type=int,\n",
        "                    help=\"number of data loading workers\")\n",
        "parser.add_argument(\"--checkpoint_freq\", type=int, default=25,\n",
        "                    help=\"Save the model periodically\")\n",
        "parser.add_argument(\"--use_fp16\", type=bool_flag, default=True,\n",
        "                    help=\"whether to train with mixed precision or not\")\n",
        "parser.add_argument(\"--sync_bn\", type=str, default=\"pytorch\", help=\"synchronize bn\")\n",
        "parser.add_argument(\"--syncbn_process_group_size\", type=int, default=8, help=\"\"\" see\n",
        "                    https://github.com/NVIDIA/apex/blob/master/apex/parallel/__init__.py#L58-L67\"\"\")\n",
        "parser.add_argument(\"--dump_path\", type=str, default=\".\",\n",
        "                    help=\"experiment dump path for checkpoints and log\")\n",
        "parser.add_argument(\"--seed\", type=int, default=31, help=\"seed\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    global args\n",
        "    args = parser.parse_args()\n",
        "    init_distributed_mode(args)\n",
        "    fix_random_seeds(args.seed)\n",
        "    logger, training_stats = initialize_exp(args, \"epoch\", \"loss\")\n",
        "\n",
        "    # build data\n",
        "    train_dataset = MultiCropDataset(\n",
        "        args.data_path,\n",
        "        args.size_crops,\n",
        "        args.nmb_crops,\n",
        "        args.min_scale_crops,\n",
        "        args.max_scale_crops,\n",
        "        pil_blur=args.use_pil_blur,\n",
        "    )\n",
        "    sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        sampler=sampler,\n",
        "        batch_size=args.batch_size,\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "    logger.info(\"Building data done with {} images loaded.\".format(len(train_dataset)))\n",
        "\n",
        "    # build model\n",
        "    model = resnet_models.__dict__[args.arch](\n",
        "        normalize=True,\n",
        "        hidden_mlp=args.hidden_mlp,\n",
        "        output_dim=args.feat_dim,\n",
        "        nmb_prototypes=args.nmb_prototypes,\n",
        "    )\n",
        "    # synchronize batch norm layers\n",
        "    if args.sync_bn == \"pytorch\":\n",
        "        model = nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
        "    elif args.sync_bn == \"apex\":\n",
        "        # with apex syncbn we sync bn per group because it speeds up computation\n",
        "        # compared to global syncbn\n",
        "        process_group = apex.parallel.create_syncbn_process_group(args.syncbn_process_group_size)\n",
        "        model = apex.parallel.convert_syncbn_model(model, process_group=process_group)\n",
        "    # copy model to GPU\n",
        "    model = model.cuda()\n",
        "    if args.rank == 0:\n",
        "        logger.info(model)\n",
        "    logger.info(\"Building model done.\")\n",
        "\n",
        "    # build optimizer\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=args.base_lr,\n",
        "        momentum=0.9,\n",
        "        weight_decay=args.wd,\n",
        "    )\n",
        "    optimizer = LARC(optimizer=optimizer, trust_coefficient=0.001, clip=False)\n",
        "    warmup_lr_schedule = np.linspace(args.start_warmup, args.base_lr, len(train_loader) * args.warmup_epochs)\n",
        "    iters = np.arange(len(train_loader) * (args.epochs - args.warmup_epochs))\n",
        "    cosine_lr_schedule = np.array([args.final_lr + 0.5 * (args.base_lr - args.final_lr) * (1 + \\\n",
        "                         math.cos(math.pi * t / (len(train_loader) * (args.epochs - args.warmup_epochs)))) for t in iters])\n",
        "    lr_schedule = np.concatenate((warmup_lr_schedule, cosine_lr_schedule))\n",
        "    logger.info(\"Building optimizer done.\")\n",
        "\n",
        "    # init mixed precision\n",
        "    if args.use_fp16:\n",
        "        model, optimizer = apex.amp.initialize(model, optimizer, opt_level=\"O1\")\n",
        "        logger.info(\"Initializing mixed precision done.\")\n",
        "\n",
        "    # wrap model\n",
        "    model = nn.parallel.DistributedDataParallel(\n",
        "        model,\n",
        "        device_ids=[args.gpu_to_work_on],\n",
        "        find_unused_parameters=True,\n",
        "    )\n",
        "\n",
        "    # optionally resume from a checkpoint\n",
        "    to_restore = {\"epoch\": 0}\n",
        "    restart_from_checkpoint(\n",
        "        os.path.join(args.dump_path, \"checkpoint.pth.tar\"),\n",
        "        run_variables=to_restore,\n",
        "        state_dict=model,\n",
        "        optimizer=optimizer,\n",
        "        amp=apex.amp,\n",
        "    )\n",
        "    start_epoch = to_restore[\"epoch\"]\n",
        "\n",
        "    # build the queue\n",
        "    queue = None\n",
        "    queue_path = os.path.join(args.dump_path, \"queue\" + str(args.rank) + \".pth\")\n",
        "    if os.path.isfile(queue_path):\n",
        "        queue = torch.load(queue_path)[\"queue\"]\n",
        "    # the queue needs to be divisible by the batch size\n",
        "    args.queue_length -= args.queue_length % (args.batch_size * args.world_size)\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    for epoch in range(start_epoch, args.epochs):\n",
        "\n",
        "        # train the network for one epoch\n",
        "        logger.info(\"============ Starting epoch %i ... ============\" % epoch)\n",
        "\n",
        "        # set sampler\n",
        "        train_loader.sampler.set_epoch(epoch)\n",
        "\n",
        "        # optionally starts a queue\n",
        "        if args.queue_length > 0 and epoch >= args.epoch_queue_starts and queue is None:\n",
        "            queue = torch.zeros(\n",
        "                len(args.crops_for_assign),\n",
        "                args.queue_length // args.world_size,\n",
        "                args.feat_dim,\n",
        "            ).cuda()\n",
        "\n",
        "        # train the network\n",
        "        scores, queue = train(train_loader, model, optimizer, epoch, lr_schedule, queue)\n",
        "        training_stats.update(scores)\n",
        "\n",
        "        # save checkpoints\n",
        "        if args.rank == 0:\n",
        "            save_dict = {\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"state_dict\": model.state_dict(),\n",
        "                \"optimizer\": optimizer.state_dict(),\n",
        "            }\n",
        "            if args.use_fp16:\n",
        "                save_dict[\"amp\"] = apex.amp.state_dict()\n",
        "            torch.save(\n",
        "                save_dict,\n",
        "                os.path.join(args.dump_path, \"checkpoint.pth.tar\"),\n",
        "            )\n",
        "            if epoch % args.checkpoint_freq == 0 or epoch == args.epochs - 1:\n",
        "                shutil.copyfile(\n",
        "                    os.path.join(args.dump_path, \"checkpoint.pth.tar\"),\n",
        "                    os.path.join(args.dump_checkpoints, \"ckp-\" + str(epoch) + \".pth\"),\n",
        "                )\n",
        "        if queue is not None:\n",
        "            torch.save({\"queue\": queue}, queue_path)\n",
        "\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch, lr_schedule, queue):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "\n",
        "    softmax = nn.Softmax(dim=1).cuda()\n",
        "    model.train()\n",
        "    use_the_queue = False\n",
        "\n",
        "    end = time.time()\n",
        "    for it, inputs in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        # update learning rate\n",
        "        iteration = epoch * len(train_loader) + it\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group[\"lr\"] = lr_schedule[iteration]\n",
        "\n",
        "        # normalize the prototypes\n",
        "        with torch.no_grad():\n",
        "            w = model.module.prototypes.weight.data.clone()\n",
        "            w = nn.functional.normalize(w, dim=1, p=2)\n",
        "            model.module.prototypes.weight.copy_(w)\n",
        "\n",
        "        # ============ multi-res forward passes ... ============\n",
        "        embedding, output = model(inputs)\n",
        "        embedding = embedding.detach()\n",
        "        bs = inputs[0].size(0)\n",
        "\n",
        "        # ============ swav loss ... ============\n",
        "        loss = 0\n",
        "        for i, crop_id in enumerate(args.crops_for_assign):\n",
        "            with torch.no_grad():\n",
        "                out = output[bs * crop_id: bs * (crop_id + 1)]\n",
        "\n",
        "                # time to use the queue\n",
        "                if queue is not None:\n",
        "                    if use_the_queue or not torch.all(queue[i, -1, :] == 0):\n",
        "                        use_the_queue = True\n",
        "                        out = torch.cat((torch.mm(\n",
        "                            queue[i],\n",
        "                            model.module.prototypes.weight.t()\n",
        "                        ), out))\n",
        "                    # fill the queue\n",
        "                    queue[i, bs:] = queue[i, :-bs].clone()\n",
        "                    queue[i, :bs] = embedding[crop_id * bs: (crop_id + 1) * bs]\n",
        "                # get assignments\n",
        "                q = out / args.epsilon\n",
        "                if args.improve_numerical_stability:\n",
        "                    M = torch.max(q)\n",
        "                    dist.all_reduce(M, op=dist.ReduceOp.MAX)\n",
        "                    q -= M\n",
        "                q = torch.exp(q).t()\n",
        "                q = distributed_sinkhorn(q, args.sinkhorn_iterations)[-bs:]\n",
        "\n",
        "            # cluster assignment prediction\n",
        "            subloss = 0\n",
        "            for v in np.delete(np.arange(np.sum(args.nmb_crops)), crop_id):\n",
        "                p = softmax(output[bs * v: bs * (v + 1)] / args.temperature)\n",
        "                subloss -= torch.mean(torch.sum(q * torch.log(p), dim=1))\n",
        "            loss += subloss / (np.sum(args.nmb_crops) - 1)\n",
        "        loss /= len(args.crops_for_assign)\n",
        "\n",
        "        # ============ backward and optim step ... ============\n",
        "        optimizer.zero_grad()\n",
        "        if args.use_fp16:\n",
        "            with apex.amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                scaled_loss.backward()\n",
        "        else:\n",
        "            loss.backward()\n",
        "        # cancel some gradients\n",
        "        if iteration < args.freeze_prototypes_niters:\n",
        "            for name, p in model.named_parameters():\n",
        "                if \"prototypes\" in name:\n",
        "                    p.grad = None\n",
        "        optimizer.step()\n",
        "\n",
        "        # ============ misc ... ============\n",
        "        losses.update(loss.item(), inputs[0].size(0))\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "        if args.rank ==0 and it % 50 == 0:\n",
        "            logger.info(\n",
        "                \"Epoch: [{0}][{1}]\\t\"\n",
        "                \"Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"\n",
        "                \"Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\"\n",
        "                \"Loss {loss.val:.4f} ({loss.avg:.4f})\\t\"\n",
        "                \"Lr: {lr:.4f}\".format(\n",
        "                    epoch,\n",
        "                    it,\n",
        "                    batch_time=batch_time,\n",
        "                    data_time=data_time,\n",
        "                    loss=losses,\n",
        "                    lr=optimizer.optim.param_groups[0][\"lr\"],\n",
        "                )\n",
        "            )\n",
        "    return (epoch, losses.avg), queue\n",
        "\n",
        "\n",
        "def distributed_sinkhorn(Q, nmb_iters):\n",
        "    with torch.no_grad():\n",
        "        Q = shoot_infs(Q)\n",
        "        sum_Q = torch.sum(Q)\n",
        "        dist.all_reduce(sum_Q)\n",
        "        Q /= sum_Q\n",
        "        r = torch.ones(Q.shape[0]).cuda(non_blocking=True) / Q.shape[0]\n",
        "        c = torch.ones(Q.shape[1]).cuda(non_blocking=True) / (args.world_size * Q.shape[1])\n",
        "        for it in range(nmb_iters):\n",
        "            u = torch.sum(Q, dim=1)\n",
        "            dist.all_reduce(u)\n",
        "            u = r / u\n",
        "            u = shoot_infs(u)\n",
        "            Q *= u.unsqueeze(1)\n",
        "            Q *= (c / torch.sum(Q, dim=0)).unsqueeze(0)\n",
        "        return (Q / torch.sum(Q, dim=0, keepdim=True)).t().float()\n",
        "\n",
        "\n",
        "def shoot_infs(inp_tensor):\n",
        "    \"\"\"Replaces inf by maximum of tensor\"\"\"\n",
        "    mask_inf = torch.isinf(inp_tensor)\n",
        "    ind_inf = torch.nonzero(mask_inf)\n",
        "    if len(ind_inf) > 0:\n",
        "        for ind in ind_inf:\n",
        "            if len(ind) == 2:\n",
        "                inp_tensor[ind[0], ind[1]] = 0\n",
        "            elif len(ind) == 1:\n",
        "                inp_tensor[ind[0]] = 0\n",
        "        m = torch.max(inp_tensor)\n",
        "        for ind in ind_inf:\n",
        "            if len(ind) == 2:\n",
        "                inp_tensor[ind[0], ind[1]] = m\n",
        "            elif len(ind) == 1:\n",
        "                inp_tensor[ind[0]] = m\n",
        "    return inp_tensor\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-57390c14b83c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mapex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLARC\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLARC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from src.utils import (\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mbool_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0minitialize_exp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJzaqoEonXeg"
      },
      "source": [
        "#Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-DVD9VtmEw8"
      },
      "source": [
        "**Evaluation - Semi-supervised learning on ImageNet** (10 % Labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbJ1t6FZmEho",
        "outputId": "b40ff065-6cfe-4c72-db89-2f3c23a2a107"
      },
      "source": [
        "!python -m torch.distributed.launch --nproc_per_node=8 eval_semisup.py \\\n",
        "--data_path /path/to/imagenet \\\n",
        "--pretrained /path/to/checkpoints/swav_800ep_pretrain.pth.tar \\\n",
        "--labels_perc \"10\" \\\n",
        "--lr 0.01 \\\n",
        "--lr_last_layer 0.2"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*****************************************\n",
            "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
            "*****************************************\n",
            "/usr/bin/python3: can't open file 'eval_semisup.py': [Errno 2] No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/launch.py\", line 260, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/distributed/launch.py\", line 256, in main\n",
            "    cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-u', 'eval_semisup.py', '--local_rank=7', '--data_path', '/path/to/imagenet', '--pretrained', '/path/to/checkpoints/swav_800ep_pretrain.pth.tar', '--labels_perc', '10', '--lr', '0.01', '--lr_last_layer', '0.2']' returned non-zero exit status 2.\n",
            "/usr/bin/python3: can't open file 'eval_semisup.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file 'eval_semisup.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file 'eval_semisup.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file 'eval_semisup.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file 'eval_semisup.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file 'eval_semisup.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file 'eval_semisup.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7G_tnzmmQ7w"
      },
      "source": [
        "**Evaluation - Semi-supervised learning on ImageNet** (1 % Labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmm8SjqXmQtp"
      },
      "source": [
        "python -m torch.distributed.launch --nproc_per_node=8 eval_semisup.py \\\n",
        "--data_path /path/to/imagenet \\\n",
        "--pretrained /path/to/checkpoints/swav_800ep_pretrain.pth.tar \\\n",
        "--labels_perc \"1\" \\\n",
        "--lr 0.02 \\\n",
        "--lr_last_layer 5"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}